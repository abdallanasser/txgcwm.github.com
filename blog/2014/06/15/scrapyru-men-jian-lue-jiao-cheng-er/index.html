
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Scrapy入门简略教程（二） - 残剑</title>
  <meta name="author" content="残剑">

  
  <meta name="description" content="What just happened under the hood? Scrapy为爬虫中的start_urls属性中每个URL创建了一个scrapy.http.Request对象 ，并把parse方法作为回调函数指定给爬虫。 这些Request会被调度，执行，scrapy.http. &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://txgcwm.github.io/blog/2014/06/15/scrapyru-men-jian-lue-jiao-cheng-er">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="残剑" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-50842363-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">残剑</a></h1>
  
    <h2>Stop walking today and you'll have to run tomorrow!</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:txgcwm.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Scrapy入门简略教程（二）</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-15T13:44:00+08:00" pubdate data-updated="true">Jun 15<span>th</span>, 2014</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><h1>What just happened under the hood?</h1>

<p>Scrapy为爬虫中的<code>start_urls</code>属性中每个URL创建了一个<code>scrapy.http.Request</code>对象 ，并把<code>parse</code>方法作为回调函数指定给爬虫。</p>

<p>这些<code>Request</code>会被调度，执行，<code>scrapy.http.Response</code>对象被返回，结果也被反馈给爬虫，之后通过<code>parse()</code>方法解析。</p>

<h1>Extracting Items</h1>

<h2>Introduction to Selectors</h2>

<p>有很多方法从网站中提取数据。Scrapy使用一种叫做Scrapy Selectors的机制，它基于XPath或者是CSS表达式。如果想了解更多selectors和其它机制，可查阅<a href="http://doc.scrapy.org/en/latest/topics/selectors.html#topics-selectors">Selectors documentation</a>。</p>

<p>以下是XPath表达式的例子和它们的含义：</p>

<ul>
<li><code>/html/head/title</code>: 选择HTML文档<code>&lt;head&gt;</code>元素下面的<code>&lt;title&gt;</code>标签。</li>
<li><code>/html/head/title/text()</code>: 选择前面提到的<code>&lt;title&gt;</code>元素下面的文本内容。</li>
<li><code>//td</code>: 选择所有 <code>&lt;td&gt;</code>元素。</li>
<li><code>//div[@class="mine"]</code>: 选择所有包含<code>class="mine"</code>属性的<code>div</code>标签元素。</li>
</ul>


<p>这只是几个使用XPath的简单例子，但是实际上XPath非常强大。如果你想了解更多XPATH的内容，我们向你推荐这个<a href="http://www.w3schools.com/XPath/default.asp">XPath教程</a>。</p>

<p>为了方便使用XPaths，Scrapy提供XPath<code>Selector</code>类， 有两种方式可以选择，<code>HtmlResponse</code>(HTML数据解析) 和<code>XmlResponse</code>(XML数据解析)。</p>

<p>使用XPath选择器，Scrapy提供了一个<code>Selector</code>类，它实例化一个<code>Htmlresponse</code>或<code>Xmlresponse</code>对象作为第一个参数。</p>

<p>你可以看到selectors作为对象表示在文档结构节点。所以，第一个实例化selectors是与根节点相关联，或整个文档。</p>

<p>Selectors有四种基本方法（具体的使用请查看API文档）：</p>

<ul>
<li><code>path()</code>：返回selectors列表, 每一个select表示一个xpath参数表达式选择的节点。</li>
<li><code>css()</code>: 返回selectors列表, 每一个select表示一个CSS参数表达式选择的节点。</li>
<li><code>extract()</code>：返回一个unicode字符串，该字符串为XPath选择器返回的数据。</li>
<li><code>re()</code>： 返回unicode字符串列表，字符串作为参数由正则表达式提取出来。</li>
</ul>


<!--more-->


<h2>Trying Selectors in the Shell</h2>

<p>为了演示Selectors的用法，我们将用到内建的Scrapy shell，这需要系统已经安装IPython (一个扩展的python交互环境)。</p>

<p>要开始shell，必须进入项目顶层目录，然后输入：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>scrapy shell "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"</span></code></pre></td></tr></table></div></figure>


<p>shell会输入以下的类似信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ ... Scrapy log here ... ]
</span><span class='line'>
</span><span class='line'>2014-01-23 17:11:42-0400 [default] DEBUG: Crawled (200) &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt; (referer: None)
</span><span class='line'>[s] Available Scrapy objects:
</span><span class='line'>[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x3636b50&gt;
</span><span class='line'>[s]   item       {}
</span><span class='line'>[s]   request    &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;
</span><span class='line'>[s]   response   &lt;200 http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;
</span><span class='line'>[s]   sel        &lt;Selector xpath=None data=u'&lt;html&gt;\r\n&lt;head&gt;\r\n&lt;meta http-equiv="Conten'&gt;
</span><span class='line'>[s]   settings   &lt;CrawlerSettings module=None&gt;
</span><span class='line'>[s]   spider     &lt;Spider 'default' at 0x3cebf50&gt;
</span><span class='line'>[s] Useful shortcuts:
</span><span class='line'>[s]   shelp()           Shell help (print this help)
</span><span class='line'>[s]   fetch(req_or_url) Fetch request (or URL) and update local objects
</span><span class='line'>[s]   view(response)    View response in a browser
</span><span class='line'>
</span><span class='line'>In [1]:</span></code></pre></td></tr></table></div></figure>


<p>Shell加载完毕后，将获得回应，这些内容被存储在本地变量<code>response</code>中，所以如果你输入<code>response.body</code>将会看到response的body部分，或者输入<code>response.headers</code>来查看它的header部分。</p>

<p>Shell通过变量<code>sel</code>为这个response提前初始化一个selector，这个selector基于response的类型自动选择最佳的解析规则（XML或者HTML）。</p>

<p>我们来看看里面有什么：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>In [1]: sel.xpath('//title')
</span><span class='line'>Out[1]: [&lt;Selector xpath='//title' data=u'&lt;title&gt;Open Directory - Computers: Progr'&gt;]
</span><span class='line'>
</span><span class='line'>In [2]: sel.xpath('//title').extract()
</span><span class='line'>Out[2]: [u'&lt;title&gt;Open Directory - Computers: Programming: Languages: Python: Books&lt;/title&gt;']
</span><span class='line'>
</span><span class='line'>In [3]: sel.xpath('//title/text()')
</span><span class='line'>Out[3]: [&lt;Selector xpath='//title/text()' data=u'Open Directory - Computers: Programming:'&gt;]
</span><span class='line'>
</span><span class='line'>In [4]: sel.xpath('//title/text()').extract()
</span><span class='line'>Out[4]: [u'Open Directory - Computers: Programming: Languages: Python: Books']
</span><span class='line'>
</span><span class='line'>In [5]: sel.xpath('//title/text()').re('(\w+):')
</span><span class='line'>Out[5]: [u'Computers', u'Programming', u'Languages', u'Python']</span></code></pre></td></tr></table></div></figure>


<h2>Extracting the data</h2>

<p>现在我们尝试从网页中提取一些真正的数据。</p>

<p>你可以在控制台输入<code>response.body</code>，检查源代码中的<code>XPaths</code>是否与预期相同。然而，检查HTML源代码是件很枯燥的事情。为了使事情变得简单，我们使用类似Firebug的Firefox扩展插件。更多信息请查看<a href="http://doc.scrapy.org/en/latest/topics/firebug.html#topics-firebug">Using Firebug for scraping</a>和<a href="http://doc.scrapy.org/en/latest/topics/firefox.html#topics-firefox">Using Firefox for scraping</a>。</p>

<p>检查源代码后，你会发现我们需要的数据在<code>&lt;ul&gt;</code>元素中，事实上是第二个<code>&lt;ul&gt;</code>。</p>

<p>我们可以通过如下命令选出每个站点中的<code>&lt;li&gt;</code>元素:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sel.xpath('//ul/li')</span></code></pre></td></tr></table></div></figure>


<p>站点的描述信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sel.xpath('//ul/li/text()').extract()</span></code></pre></td></tr></table></div></figure>


<p>站点的标题：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sel.xpath('//ul/li/a/text()').extract()</span></code></pre></td></tr></table></div></figure>


<p>站点的链接：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sel.xpath('//ul/li/a/@href').extract()</span></code></pre></td></tr></table></div></figure>


<p>正如我们前面说的那样，每一个<code>.xpath</code>会返回一个selectors的列表，所以我们可以结合<code>.xpath()</code>去挖掘更深的节点。我们将会用到这些特性，所以:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sites = sel.xpath('//ul/li')
</span><span class='line'>for site in sites:
</span><span class='line'>    title = site.xpath('a/text()').extract()
</span><span class='line'>    link = site.xpath('a/@href').extract()
</span><span class='line'>    desc = site.xpath('text()').extract()
</span><span class='line'>    print title, link, desc</span></code></pre></td></tr></table></div></figure>


<p>我们把这些代码添加到爬虫中：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>from scrapy.spider import Spider
</span><span class='line'>from scrapy.selector import Selector
</span><span class='line'>
</span><span class='line'>class DmozSpider(Spider):
</span><span class='line'>    name = "dmoz"
</span><span class='line'>    allowed_domains = ["dmoz.org"]
</span><span class='line'>    start_urls = [
</span><span class='line'>        "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/",
</span><span class='line'>        "http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"
</span><span class='line'>    ]
</span><span class='line'>
</span><span class='line'>    def parse(self, response):
</span><span class='line'>        sel = Selector(response)
</span><span class='line'>        sites = sel.xpath('//ul/li')
</span><span class='line'>        for site in sites:
</span><span class='line'>            title = site.xpath('a/text()').extract()
</span><span class='line'>            link = site.xpath('a/@href').extract()
</span><span class='line'>            desc = site.xpath('text()').extract()
</span><span class='line'>            print title, link, desc</span></code></pre></td></tr></table></div></figure>


<p>我们通过scrapy.selector将Selector类导入及初始化一个Selector实例。现在可以指定我们的XPaths，如在shell中做的那样。我们尝试重新抓取dmoz.org站点，你将会在你的输出平台看到站点的一些信息，输入如下的命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>scrapy crawl dmoz</span></code></pre></td></tr></table></div></figure>


<h2>Using our item</h2>

<p>Item对象是用户自定义的python字典，你可以获取它们每个字段的值(即之前定义的类的属性)，它使用了标准的字典语法，如下所示:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt;&gt;&gt; item = DmozItem()
</span><span class='line'>&gt;&gt;&gt; item['title'] = 'Example title'
</span><span class='line'>&gt;&gt;&gt; item['title']
</span><span class='line'>'Example title'</span></code></pre></td></tr></table></div></figure>


<p>Spiders希望将其抓取的数据存放到<code>Item</code>对象中。为了返回我们抓取的数据，Spider的最终代码应当是这样:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>from scrapy.spider import Spider
</span><span class='line'>from scrapy.selector import Selector
</span><span class='line'>
</span><span class='line'>from tutorial.items import DmozItem
</span><span class='line'>
</span><span class='line'>class DmozSpider(Spider):
</span><span class='line'>    name = "dmoz"
</span><span class='line'>    allowed_domains = ["dmoz.org"]
</span><span class='line'>    start_urls = [
</span><span class='line'>        "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/",
</span><span class='line'>        "http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"
</span><span class='line'>    ]
</span><span class='line'>
</span><span class='line'>    def parse(self, response):
</span><span class='line'>        sel = Selector(response)
</span><span class='line'>        sites = sel.xpath('//ul/li')
</span><span class='line'>        items = []
</span><span class='line'>        for site in sites:
</span><span class='line'>            item = DmozItem()
</span><span class='line'>            item['title'] = site.xpath('a/text()').extract()
</span><span class='line'>            item['link'] = site.xpath('a/@href').extract()
</span><span class='line'>            item['desc'] = site.xpath('text()').extract()
</span><span class='line'>            items.append(item)
</span><span class='line'>        return items</span></code></pre></td></tr></table></div></figure>


<p>再次抓取dmoz.org站点的信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[dmoz] DEBUG: Scraped from &lt;200 http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;
</span><span class='line'>     {'desc': [u' - By David Mertz; Addison Wesley. Book in progress, full text, ASCII format. Asks for feedback. [author website, Gnosis Software, Inc.\n],
</span><span class='line'>      'link': [u'http://gnosis.cx/TPiP/'],
</span><span class='line'>      'title': [u'Text Processing in Python']}
</span><span class='line'>[dmoz] DEBUG: Scraped from &lt;200 http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;
</span><span class='line'>     {'desc': [u' - By Sean McGrath; Prentice Hall PTR, 2000, ISBN 0130211192, has CD-ROM. Methods to build XML applications fast, Python tutorial, DOM and SAX, new Pyxie open source XML processing library. [Prentice Hall PTR]\n'],
</span><span class='line'>      'link': [u'http://www.informit.com/store/product.aspx?isbn=0130211192'],
</span><span class='line'>      'title': [u'XML Processing with Python']}</span></code></pre></td></tr></table></div></figure>


<h1>Storing the scraped data</h1>

<p>保存抓取的信息的最简单方法就是使用<a href="http://doc.scrapy.org/en/latest/topics/feed-exports.html#topics-feed-exports">Feed exports</a>，使用如下的命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>scrapy crawl dmoz -o items.json -t json</span></code></pre></td></tr></table></div></figure>


<p>所有抓取的items将以JSON格式被保存在新生成的<code>items.json</code>文件中。</p>

<p>在小型的项目中（如这个教程中的例子），这些已经足够。然而，如果你想用抓取的items做更复杂的事情，你可以写一个<a href="http://doc.scrapy.org/en/latest/topics/item-pipeline.html#topics-item-pipeline">Item Pipeline</a>(条目管道)。在项目创建的时候，一个专门用于条目管道的占位符文件随着items一起被建立，在<code>tutorial/pipelines.py</code>中。如果你只需要存取这些抓取后的items的话，就不需要去实现任何的条目管道。</p>

<p><big>注：</big>整个Scrapy的入门教程写得比较杂乱，包含了翻译部分和自己写的测试小例。</p>

<p><td></td>
<big>参考文章</big></p>

<p><a href="http://doc.scrapy.org/en/latest/intro/overview.html">Scrapy at a glance</a>     <br/>
<a href="http://www.cnblogs.com/txw1958/archive/2012/07/16/scrapy-tutorial.html">Scrapy入门教程</a><br/>
<a href="http://www.biaodianfu.com/mplementation-of-targeted-crawling-system.html">聚焦爬虫：定向抓取系统的实现方法</a><br/>
<a href="http://lujiesky.blog.51cto.com/332319/1328176">开源python网络爬虫框架Scrapy</a><br/>
<a href="http://www.yakergong.net/blog/archives/500">使用scrapy进行大规模抓取(一)</a><br/>
<a href="http://blog.csdn.net/pleasecallmewhy/article/details/19642329">Python网络爬虫（12）：爬虫框架Scrapy的第一个爬虫示例入门教程</a><br/>
<a href="http://www.searchtb.com/2011/07/%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%8A%93%E5%8F%96%E9%9B%86%E7%BE%A4.html?spm=0.0.0.0.oD8o9v">快速构建实时抓取集群</a> <br/>
<a href="http://www.pythontab.com/html/2013/pythonhexinbiancheng_0814/541.html">python爬虫框架scrapy实例详解</a> <br/>
<a href="http://blog.pluskid.org/?p=366">Scrapy 轻松定制网络爬虫</a> <br/>
<a href="https://github.com/scrapinghub">Scrapinghub</a><br/>
<a href="http://www.kankanews.com/ICkengine/archives/94817.shtml">使用python，scrapy写（定制）爬虫的经验，资料，杂</a></p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">残剑</span></span>

      








  


<time datetime="2014-06-15T13:44:00+08:00" pubdate data-updated="true">Jun 15<span>th</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/wang-luo-pa-chong/'>网络爬虫</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/06/08/da-ge-%2Cbie-pao-ya/" title="Previous Post: 大哥，别跑呀">&laquo; 大哥，别跑呀</a>
      
      
        <a class="basic-alignment right" href="/blog/2014/06/20/centosan-zhuang-svn/" title="Next Post: CentOS安装SVN">CentOS安装SVN &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
	<h1>QR-Code<abbr title="The word 'QR Code' is a registered trademark of DENSO WAVE INCORPORATED. It applies only for the word 'QR Code', not for image.">&trade;</abbr></h1>
	<a href="http://txgcwm.github.io/blog/2014/06/15/scrapyru-men-jian-lue-jiao-cheng-er/"><img src="http://chart.apis.google.com/chart?chs=180x180&cht=qr&chld=|0&chco=165B94&chl=http://txgcwm.github.io/blog/2014/06/15/scrapyru-men-jian-lue-jiao-cheng-er/" alt="post-qrcode"></a>
</section>

<section>
	<h1>新浪微博</h1>
	<ul id="weibo">
		<li>
		<iframe
			width="100%"
			height="750"
			class="share_self"
			frameborder="0"
			scrolling="no"    
			src="http://widget.weibo.com/weiboshow/index.php?width=0&height=750&&fansRow=2&ptype=1&speed=0&skin=5&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=3647512137&verifier=77f2c556&dpc=1">
		</iframe>
		</li>
	</ul>
</section>

<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/06/28/gccbian-yi-xuan-xiang/">GCC编译选项</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/20/centosan-zhuang-svn/">CentOS安装SVN</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/15/scrapyru-men-jian-lue-jiao-cheng-er/">Scrapy入门简略教程（二）</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/08/da-ge-%2Cbie-pao-ya/">大哥，别跑呀</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/08/you-%5B%3F%5D-chong-ai-jiao-zuo-fang-shou/">有一种爱叫做放手</a>
      </li>
    
  </ul>
</section>

<section id="comment_sidebar">
<h1>Recent Comments</h1>

<script type="text/javascript" src="http://txgcwm.disqus.com/recent_comments_widget.js?num_items=5&hide_avatars=0&avatar_size=32&excerpt_length=20"></script><a href="http://disqus.com/">Powered by Disqus</a>

</section>

<section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/android/'>Android (1)</a></li>
<li class='category'><a href='/blog/categories/c-c/'>C/C++ (13)</a></li>
<li class='category'><a href='/blog/categories/ide/'>IDE (2)</a></li>
<li class='category'><a href='/blog/categories/octopress/'>Octopress (6)</a></li>
<li class='category'><a href='/blog/categories/python/'>Python (1)</a></li>
<li class='category'><a href='/blog/categories/shell/'>Shell (7)</a></li>
<li class='category'><a href='/blog/categories/unix-linux/'>Unix/Linux (29)</a></li>
<li class='category'><a href='/blog/categories/chan-pin-guan-cha/'>产品观察 (9)</a></li>
<li class='category'><a href='/blog/categories/nei-he-qu-dong/'>内核/驱动 (1)</a></li>
<li class='category'><a href='/blog/categories/bo-gu-tong-jin/'>博古通今 (4)</a></li>
<li class='category'><a href='/blog/categories/qian-ru-shi-kai-fa/'>嵌入式开发 (1)</a></li>
<li class='category'><a href='/blog/categories/kai-yuan-ku/'>开源库 (5)</a></li>
<li class='category'><a href='/blog/categories/ying-shi-qu-shang-xi/'>影视曲赏析 (5)</a></li>
<li class='category'><a href='/blog/categories/wei-fang-tan/'>微访谈 (15)</a></li>
<li class='category'><a href='/blog/categories/qing-gan-tian-di/'>情感天地 (2)</a></li>
<li class='category'><a href='/blog/categories/shu-ju-jie-gou-suan-fa/'>数据结构算法 (3)</a></li>
<li class='category'><a href='/blog/categories/lu-xing-san-ji/'>旅行散记 (19)</a></li>
<li class='category'><a href='/blog/categories/sha-long-ji-yao/'>沙龙纪要 (1)</a></li>
<li class='category'><a href='/blog/categories/liu-mei-ti-yin-shi-pin/'>流媒体/音视频 (3)</a></li>
<li class='category'><a href='/blog/categories/wang-luo-ying-yong/'>网络应用 (4)</a></li>
<li class='category'><a href='/blog/categories/wang-luo-pa-chong/'>网络爬虫 (4)</a></li>
<li class='category'><a href='/blog/categories/cha-yu-jiu-hou/'>茶余酒后 (49)</a></li>
<li class='category'><a href='/blog/categories/shi-yi-fang/'>试衣坊 (2)</a></li>
<li class='category'><a href='/blog/categories/shi-yi-ren-sheng/'>诗意人生 (4)</a></li>
<li class='category'><a href='/blog/categories/lu-you-qi-fang-huo-qiang/'>路由器/防火墙 (1)</a></li>
<li class='category'><a href='/blog/categories/shen-bian-de-gu-shi/'>身边的故事 (8)</a></li>

  </ul>
</section>
<section>
	<h1>技术博客</h1>
  	<ul>
    <li>
      <a href="http://coolshell.cn/">酷壳</a>
    </li>
    <li>
      <a href="http://mindhacks.cn/">刘未鹏</a>
    </li>
    <li>
      <a href="http://blog.codingnow.com/">云风</a>
    </li>
    <li>
      <a href="http://www.cnblogs.com/Solstice/">陈硕</a>
    </li>
	<li>
      <a href="http://rdc.taobao.com/blog/cs/">淘宝核心系统团队博客</a>
    </li>
	<li>
      <a href="http://www.searchtb.com/">搜索技术博客－淘宝</a>
    </li>
	<li>
      <a href="http://www.matrix67.com/blog/">matrix67</a>
    </li>
	<li>
      <a href="http://blog.csdn.net/v_JULY_v">结构之法 算法之道</a>
    </li>
    <li>
      <a href="http://ioutlier.com/">Life As An Outlier</a>
    </li>
	<li>
      <a href="http://www.diguage.com/">地瓜哥</a>
    </li>
	<li>
      <a href="http://blog.csdn.net/huangminqiang201209">生命不息，奋斗不止</a>
    </li>
	<li>
      <a href="http://blog.csdn.net/tianmo2010">tianmo2010的专栏</a>
    </li>                          
	<li>
      <a href="http://tonybai.com/">Tony Bai</a>
    </li>        
	<li>
      <a href="http://www.roboby.com/">Roboby's Home</a>
    </li>
	<li>
      <a href="http://www.zhizhihu.com/">丕子</a>
    </li>
	<li>
      <a href="http://www.wuzesheng.com/">小武哥的博客</a>
    </li>
	<li>
      <a href="http://imtx.me">Tualatrix</a>
    </li>         
	<li>
      <a href="http://taosay.net/">道哥的黑板报</a>
    </li>
	<li>
      <a href="http://news.dbanotes.net/news">小道消息</a>
    </li>
	<li>
      <a href="http://www.cnblogs.com/ma6174/">ma6174</a>
    </li>                          
	<li>
      <a href="http://www.ofgeek.com/">极客所有</a>
    </li>
	<li>
      <a href="http://web2hack.org/">Web2.0 Hacking</a>
    </li>
	<li>
      <a href="http://www.yqshare.com/">记忆碎片</a>
    </li>                
  	<li>
      <a href="http://www.hiadmin.org/">Smart Testing</a>
    </li>
	<li>
      <a href="http://wmnmtm.blog.163.com/blog/#m=0">加菲猫</a>
    </li>
	<li>
      <a href="http://www.debugfs.com/">DeBugFs</a>
    </li>                                                                                 
	<li>
      <a href="http://www.sinosky.org/">SinoSky</a>
    </li>
	<li>
      <a href="http://www.isdiary.com/">冬不落</a>
    </li>
	<li>
      <a href="http://www.2fz1.com/">二分之一</a>
    </li>         
	<li>
      <a href="http://chuanliang.wordpress.com/">出家如初,成佛有余</a>
    </li>
	<li>
      <a href="http://xiaoxia.org/">Xiaoxia[PG]</a>
    </li>
	<li>
      <a href="http://www.cnblogs.com/h4ckF1y/">天黑再动手</a>
    </li>             
	<li>
      <a href="http://www.wypblog.com/">过往记忆</a>
    </li>
	<li>
      <a href="http://edsionte.com/techblog/">edsionte's Linuxworld|新手区</a>
    </li>
	<li>
      <a href="http://basiccoder.com/">basic coder</a>
    </li>          
	<li>
      <a href="http://www.vpsee.com/">vpsee</a>
    </li>
	<li>
      <a href="http://magnatecha.com/">Magna Techa</a>
    </li>
	<li>
      <a href="http://www.linksprite.com/cnblog/">LinkSprite中文博客</a>
    </li>
 	<li>
      <a href="http://zwmin.com/">斑纹小鱼</a>
    </li>
	<li>
      <a href="http://www.cvchina.info/">增强视觉 | 计算机视觉 增强现实</a>
    </li>
	<li>
      <a href="http://wangcong.org/blog/">A Geek's Page</a>
    </li>                
	<li>
      <a href="http://bachiscoding.com/">巴赫在编码</a>
    </li>
	<li>
      <a href="http://www.pyshell.com/">PyShell</a>
    </li>
	<li>
      <a href="http://blog.wgzhao.com/">Linux|系统管理|WEB开发</a>
    </li>
	<li>
      <a href="http://www.icnote.com/">博爱老头的草屋</a>
    </li>
	<li>
      <a href="http://daodao.org/">盗盗</a>
    </li>
	<li>
      <a href="http://jixiuf.github.io/index.html">一个人的狂欢</a>
    </li>
	<li>
      <a href="http://emacser.com/">Emacs中文网</a>
    </li>
	<li>
      <a href="http://www.zhangjunjie.net/">张俊杰·软件设计 – 与软件的灵魂共舞</a>
    </li>                                                             
	<li>
      <a href="http://blog.boluotou.com/">菠萝头说</a>
    </li>
	<li>
      <a href="http://blog.log4d.com/">Log4D</a>
    </li>
	<li>
      <a href="http://dinever.com/">dinever</a>
    </li>
	<li>
      <a href="http://ecvip.org/">黄海均的博客</a>
    </li>
  </ul>
</section>
<section>
	<h1>License</h1>
	<a><img left src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" style="border-width:0" alt="Creative Commons License"></a>
	<br>
	Except where otherwise noted, content on this site is licensed under a
	<a href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US" rel="license">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>. 
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.4.3/jquery.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){

  // hide #back-top first
  $("#back-top").hide();
  
  // fade in #back-top
  $(function () {
      $(window).scroll(function () {
          if ($(this).scrollTop() > 100) {
              $('#back-top').fadeIn();
          } else {
              $('#back-top').fadeOut();
          }
      });

      // scroll body to 0px on click
      $('#back-top a').click(function () {
          $('body,html').animate({
              scrollTop: 0
          }, 800);
          return false;
      });
  });

});
</script>

<style type="text/css">
#back-top {
  position: fixed;
  bottom: 50px;
  right: 100px;
}

#back-top a {
  width: 80px;
  display: block;
  text-align: center;
  font: 11px/100% Arial, Helvetica, sans-serif;
  text-transform: uppercase;
  text-decoration: none;
  color: #bbb;

  /* transition */
  -webkit-transition: 1s;
  -moz-transition: 1s;
  transition: 1s;
}
#back-top a:hover {
  color: #000;
}

/* arrow icon (span tag) */
#back-top span {
  width: 80px;
  height: 80px;
  display: block;
  margin-bottom: 7px;
  background: #ddd url(/images/top.png) no-repeat center center;

  /* rounded corners */
  -webkit-border-radius: 15px;
  -moz-border-radius: 15px;
  border-radius: 15px;

  /* transition */
  -webkit-transition: 1s;
  -moz-transition: 1s;
  transition: 1s;
}
#back-top a:hover span {
  background-color: #888;
}
</style>

<p id="back-top">
  <a href="#top"><span></span></a>
</p>

<p>
  Copyright © 2014 - 残剑 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'txgcwm';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://txgcwm.github.io/blog/2014/06/15/scrapyru-men-jian-lue-jiao-cheng-er/';
        var disqus_url = 'http://txgcwm.github.io/blog/2014/06/15/scrapyru-men-jian-lue-jiao-cheng-er/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
